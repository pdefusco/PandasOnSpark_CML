{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bc47cd6-5d67-4e9e-97cc-5801586b31c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.local/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /runtime-addons/cmladdon-python-2.0.30-b114/opt/cmladdons/python/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/site-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /runtime-addons/cmladdon-python-2.0.30-b114/opt/cmladdons/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /runtime-addons/cmladdon-python-2.0.30-b114/opt/cmladdons/python/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: PyArrow in ./.local/lib/python3.7/site-packages (9.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/site-packages (from PyArrow) (1.19.4)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install PyArrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14f11bc9-a008-4532-bbbe-db42d6af5f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.pandas as pds\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f63fd29-8fdd-4151-854c-d1bc4b796960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration  Discount\n",
      "0    Spark  22000   30days    1000.0\n",
      "1  PySpark  25000   50days    2300.0\n",
      "2   Hadoop  23000   55days    1000.0\n",
      "3   Python  24000   40days    1200.0\n",
      "4   Pandas  26000   60days    2500.0\n",
      "5   Hadoop  25000   35days       NaN\n",
      "6    Spark  25000   30days    1400.0\n",
      "7   Python  22000   50days    1600.0\n",
      "8       NA   1500   40days       0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create pandas DataFrame\n",
    "technologies   = ({\n",
    "    'Courses':[\"Spark\",\"PySpark\",\"Hadoop\",\"Python\",\"Pandas\",\"Hadoop\",\"Spark\",\"Python\",\"NA\"],\n",
    "    'Fee' :[22000,25000,23000,24000,26000,25000,25000,22000,1500],\n",
    "    'Duration':['30days','50days','55days','40days','60days','35days','30days','50days','40days'],\n",
    "    'Discount':[1000,2300,1000,1200,2500,None,1400,1600,0]\n",
    "          })\n",
    "df = pd.DataFrame(technologies)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7217445d-7738-4488-b98e-30e2e1af6275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Fee  Discount\n",
      "Courses                 \n",
      "Hadoop   48000    1000.0\n",
      "NA        1500       0.0\n",
      "Pandas   26000    2500.0\n",
      "PySpark  25000    2300.0\n",
      "Python   46000    2800.0\n",
      "Spark    47000    2400.0\n"
     ]
    }
   ],
   "source": [
    "# Use groupby() to compute the sum\n",
    "df2 = df.groupby(['Courses']).sum()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f7fed4c-177b-4233-a315-1429a26ed190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration  Discount\n",
      "0    Spark  22000   30days    1000.0\n",
      "1  PySpark  25000   50days    2300.0\n",
      "2   Hadoop  23000   55days    1000.0\n",
      "3   Python  24000   40days    1200.0\n",
      "4   Pandas  26000   60days    2500.0\n",
      "5   Hadoop  25000   35days       NaN\n",
      "6    Spark  25000   30days    1400.0\n",
      "7   Python  22000   50days    1600.0\n",
      "8       NA   1500   40days       0.0\n"
     ]
    }
   ],
   "source": [
    "import pyspark.pandas as ps\n",
    "\n",
    "# Create pandas DataFrame\n",
    "technologies   = ({\n",
    "    'Courses':[\"Spark\",\"PySpark\",\"Hadoop\",\"Python\",\"Pandas\",\"Hadoop\",\"Spark\",\"Python\",\"NA\"],\n",
    "    'Fee' :[22000,25000,23000,24000,26000,25000,25000,22000,1500],\n",
    "    'Duration':['30days','50days','55days','40days','60days','35days','30days','50days','40days'],\n",
    "    'Discount':[1000,2300,1000,1200,2500,None,1400,1600,0]\n",
    "          })\n",
    "df = ps.DataFrame(technologies)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69ad785c-e5ab-4a4c-8fbd-3ce1b820c070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Fee  Discount\n",
      "Courses                 \n",
      "NA        1500       0.0\n",
      "Pandas   26000    2500.0\n",
      "Python   46000    2800.0\n",
      "Spark    47000    2400.0\n",
      "Hadoop   48000    1000.0\n",
      "PySpark  25000    2300.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Use groupby() to compute the sum\n",
    "df2 = df.groupby(['Courses']).sum()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6338780c-f0a7-4faa-90b6-fe49411f4973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Convert Pandas API on Spark to Pandas DataFrame\n",
    "pdf = df.to_pandas()\n",
    "print(type(pdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7039fae1-d4f8-4b78-8700-201cea1055ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.pandas.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Convert Pandas DataFrame to Pandas API on Spark DataFrame\n",
    "psdf = ps.from_pandas(pdf)\n",
    "print(type(psdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44e7319a-0aa2-4d36-87a1-117e7ea7a1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "+-------+-----+--------+--------+\n",
      "|Courses|  Fee|Duration|Discount|\n",
      "+-------+-----+--------+--------+\n",
      "|  Spark|22000|  30days|  1000.0|\n",
      "|PySpark|25000|  50days|  2300.0|\n",
      "| Hadoop|23000|  55days|  1000.0|\n",
      "| Python|24000|  40days|  1200.0|\n",
      "| Pandas|26000|  60days|  2500.0|\n",
      "| Hadoop|25000|  35days|    null|\n",
      "|  Spark|25000|  30days|  1400.0|\n",
      "| Python|22000|  50days|  1600.0|\n",
      "|     NA| 1500|  40days|     0.0|\n",
      "+-------+-----+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pandas API on Spark Dataframe into a Spark DataFrame\n",
    "sdf = df.to_spark()\n",
    "print(type(sdf))\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f878b159-8557-4d72-b6cd-b2c058cf962a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14abc50b-1cb5-4c8a-bb6a-044dda03afde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
